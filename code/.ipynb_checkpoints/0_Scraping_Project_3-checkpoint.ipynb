{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Using Beautiful Soup, Reddit API and PushShift API to scrape SUBREDDITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this portion of the Project, we'll use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), [Reddit API](https://www.reddit.com/dev/api/) and [Push Shift API](https://github.com/pushshift/api) to scrape the [ProCreate](https://www.reddit.com/r/ProCreate/) and [Adobe Illustrator](https://www.reddit.com/r/AdobeIllustrator/) subreddits.\n",
    "\n",
    "We would discuss the pros and cons of the 3 different scraping mechanisms and our reasoning for picking PushShift API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "# imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [1.0 Using Beautiful Soup to Scrape](#using)\n",
    "- [2.0 Utilize Reddits API to Scrape](#reddit)\n",
    "- [3.0 Using PushShift API to Scrape](#push)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Using Beautiful Soup to Scrape<a name=\"using\"></a>\n",
    "\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n",
    "\n",
    "Source: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Beautiful SOUP function to scrape url page of REDDIT\n",
    "def scraper_dictionary (url, subreddit):\n",
    "    \n",
    "    sodos = [] \n",
    "    \n",
    "    dictlist = ['post', 'votes', 'comments','sub_reddit'] # essentially my header\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    \n",
    "    res = requests.get(url, headers=headers)\n",
    "    \n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    \n",
    "    for i in soup.find_all('div',{'data-promoted':'false'}): # Ensures adverts are ignored\n",
    "        \n",
    "        empty = []\n",
    "        \n",
    "        # Posts\n",
    "        y=i.find('a',{'data-event-action':'title'})\n",
    "        empty.append(y.text)\n",
    "    \n",
    "        # Votes\n",
    "        try:\n",
    "            y=i.find('div',{'class':'score unvoted'})\n",
    "            empty.append(int(y.text))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        # Comments\n",
    "        y = i.find('a',{'data-event-action':'comments'})\n",
    "        empty.append(y.text)\n",
    "        \n",
    "        empty.append(subreddit) # Subreddit\n",
    "        \n",
    "        sodos.append(empty)\n",
    "        \n",
    "    emptydict = []\n",
    "\n",
    "    for i in sodos:\n",
    "\n",
    "        emptydict.append(dict(zip(dictlist,i))) # This converts list of lists to dictionary \n",
    "# https://betterprogramming.pub/10-ways-to-convert-lists-to-dictionaries-in-python-d2c728d2aeb8\n",
    "\n",
    "    return emptydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create For Loop to loop through every 25 posts up to 1000 posts\n",
    "\n",
    "final_dataframe = []\n",
    "\n",
    "for i in range(0,1000,25):\n",
    "     \n",
    "    final_dataframe.extend(scraper_dictionary (f'https://old.reddit.com/r/ProCreate/?count={i}&after=t3_lrzhf4','Procreate'))\n",
    "    \n",
    "    sleep(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "procreate = pd.DataFrame(final_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 25\n",
    "is the Maximum Number of Posts Beautiful Soup could scrape automatically due to Reddit's dynamic links which ensures each page link cannot be determined with a simple logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>votes</th>\n",
       "      <th>comments</th>\n",
       "      <th>sub_reddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inumaki Togeâ€™s first word || Jujutsu Kaisen an...</td>\n",
       "      <td>2</td>\n",
       "      <td>comment</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Help - Procreate freezes/stutters frequently o...</td>\n",
       "      <td>2</td>\n",
       "      <td>4 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random access memories in honor of Daft Punk. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iâ€™ve really been enjoying this digital painter...</td>\n",
       "      <td>567</td>\n",
       "      <td>26 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Favorite free brushes?</td>\n",
       "      <td>1</td>\n",
       "      <td>comment</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Finally feeling a bit more comfortable with Pr...</td>\n",
       "      <td>4</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Close up portraitðŸ’œ</td>\n",
       "      <td>9</td>\n",
       "      <td>comment</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Wanna go camping ?</td>\n",
       "      <td>3</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>if you delete the app is there still no way to...</td>\n",
       "      <td>1</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>illustration commission by me - jvh_arts</td>\n",
       "      <td>163</td>\n",
       "      <td>11 comments</td>\n",
       "      <td>Procreate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  post  votes     comments  \\\n",
       "0    Inumaki Togeâ€™s first word || Jujutsu Kaisen an...      2      comment   \n",
       "1    Help - Procreate freezes/stutters frequently o...      2   4 comments   \n",
       "2    Random access memories in honor of Daft Punk. ...      2   3 comments   \n",
       "3    iâ€™ve really been enjoying this digital painter...    567  26 comments   \n",
       "4                               Favorite free brushes?      1      comment   \n",
       "..                                                 ...    ...          ...   \n",
       "995  Finally feeling a bit more comfortable with Pr...      4   2 comments   \n",
       "996                                 Close up portraitðŸ’œ      9      comment   \n",
       "997                                 Wanna go camping ?      3   3 comments   \n",
       "998  if you delete the app is there still no way to...      1   2 comments   \n",
       "999           illustration commission by me - jvh_arts    163  11 comments   \n",
       "\n",
       "    sub_reddit  \n",
       "0    Procreate  \n",
       "1    Procreate  \n",
       "2    Procreate  \n",
       "3    Procreate  \n",
       "4    Procreate  \n",
       "..         ...  \n",
       "995  Procreate  \n",
       "996  Procreate  \n",
       "997  Procreate  \n",
       "998  Procreate  \n",
       "999  Procreate  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procreate\n",
    "# This did not work as Reddit utilizes random numbers to throw off webscraping page by page.\n",
    "# So it just returned the same result 40 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Utilize Reddits API to Scrape<a name=\"reddit\"></a>\n",
    "\n",
    "An API to allow developers to build great products powered by Reddit because the developer community is integral to the success of the Reddit platform. The API is also to protect Reddit usersâ€™ privacy and security regardless of how they choose to consume Reddit content.\n",
    "\n",
    "Source: https://www.reddit.com/wiki/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw # This is a REDDIT Api created to Scrape Reddit pages officially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='dD37vmEd4uZG0Q',client_secret='PEzHd6SVMQtz5FR1IvSuJGKANdgXSw',user_agent='project_3')\n",
    "# I enter my reddit credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procreate New Posts\n",
    "> This returns the latest 990 to 1000 posts in ProCreate subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_new_posts = []\n",
    "\n",
    "procreate = reddit.subreddit('ProCreate')\n",
    "\n",
    "for pc_post in procreate.new(limit = 1000):\n",
    "    \n",
    "    pc_new_posts.append([pc_post.title, pc_post.score, pc_post.id, pc_post.subreddit, pc_post.url, pc_post.num_comments, pc_post.selftext, pc_post.created])\n",
    "    \n",
    "pc_new_posts = pd.DataFrame(pc_new_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pc_new_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrator New Posts\n",
    "\n",
    "> This returns the latest 990 to 1000 posts in Adobe Illustrator subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_new_posts = []\n",
    "\n",
    "ai = reddit.subreddit('AdobeIllustrator')\n",
    "\n",
    "for post in ai.new(limit = 1000):\n",
    "    \n",
    "    ai_new_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "    \n",
    "ai_new_posts = pd.DataFrame(ai_new_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ai_new_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procreate Top Posts\n",
    "\n",
    "> This returns the top 990 to 1000 posts in ProCreate subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_top_posts = []\n",
    "\n",
    "procreate = reddit.subreddit('ProCreate')\n",
    "\n",
    "for pc_post in procreate.top(limit = 1000):\n",
    "    \n",
    "    pc_top_posts.append([pc_post.title, pc_post.score, pc_post.id, pc_post.subreddit, pc_post.url, pc_post.num_comments, pc_post.selftext, pc_post.created])\n",
    "    \n",
    "pc_top_posts = pd.DataFrame(pc_top_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pc_top_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adobe Illustrator Top Posts\n",
    "\n",
    "> This returns the top 990 to 1000 posts in Adobe Illustrator subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_top_posts = []\n",
    "\n",
    "ai = reddit.subreddit('AdobeIllustrator')\n",
    "\n",
    "for post in ai.top(limit = 1000):\n",
    "    \n",
    "    ai_top_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "    \n",
    "ai_top_posts = pd.DataFrame(ai_top_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ai_top_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procreate Hot Posts\n",
    "\n",
    "> This returns the hottest 990 to 1000 posts in ProCreate subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_hot_posts = []\n",
    "\n",
    "procreate = reddit.subreddit('ProCreate')\n",
    "\n",
    "for pc_post in procreate.top(limit = 1000):\n",
    "    \n",
    "    pc_hot_posts.append([pc_post.title, pc_post.score, pc_post.id, pc_post.subreddit, pc_post.url, pc_post.num_comments, pc_post.selftext, pc_post.created])\n",
    "    \n",
    "pc_hot_posts = pd.DataFrame(pc_hot_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pc_hot_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ilustrator Hot Posts\n",
    "\n",
    "> This returns the top 990 to 1000 posts in Aodbe Illustrator subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_hot_posts = []\n",
    "\n",
    "ai = reddit.subreddit('AdobeIllustrator')\n",
    "\n",
    "for post in ai.top(limit = 2000):\n",
    "    \n",
    "    ai_hot_posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "    \n",
    "ai_hot_posts = pd.DataFrame(ai_hot_posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ai_hot_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I made an illustration during the COVID-19 loc...</td>\n",
       "      <td>2034</td>\n",
       "      <td>gwfbpd</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/x38ytci5lv251.jpg</td>\n",
       "      <td>77</td>\n",
       "      <td></td>\n",
       "      <td>1.591297e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did some linework first time in many years</td>\n",
       "      <td>1636</td>\n",
       "      <td>e89e61</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/i3l3tsnwql341.png</td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>1.575924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spongebob &amp; Patrick Minimal portrait</td>\n",
       "      <td>1579</td>\n",
       "      <td>eza5r1</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/iy28ekav54f41.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>1.580941e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drew a Casio Baby-G.</td>\n",
       "      <td>1443</td>\n",
       "      <td>ibdnt0</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/vrnv2jd19kh51.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>1.597698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The designers at Snapchat be like</td>\n",
       "      <td>1441</td>\n",
       "      <td>cq7ydh</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/rosbdsir8eg31.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "      <td>1.565808e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  I made an illustration during the COVID-19 loc...   2034  gwfbpd   \n",
       "1       I did some linework first time in many years   1636  e89e61   \n",
       "2               Spongebob & Patrick Minimal portrait   1579  eza5r1   \n",
       "3                               Drew a Casio Baby-G.   1443  ibdnt0   \n",
       "4                  The designers at Snapchat be like   1441  cq7ydh   \n",
       "\n",
       "          subreddit                                  url  num_comments body  \\\n",
       "0  AdobeIllustrator  https://i.redd.it/x38ytci5lv251.jpg            77        \n",
       "1  AdobeIllustrator  https://i.redd.it/i3l3tsnwql341.png            32        \n",
       "2  AdobeIllustrator  https://i.redd.it/iy28ekav54f41.jpg            60        \n",
       "3  AdobeIllustrator  https://i.redd.it/vrnv2jd19kh51.jpg            24        \n",
       "4  AdobeIllustrator  https://i.redd.it/rosbdsir8eg31.jpg            66        \n",
       "\n",
       "        created  \n",
       "0  1.591297e+09  \n",
       "1  1.575924e+09  \n",
       "2  1.580941e+09  \n",
       "3  1.597698e+09  \n",
       "4  1.565808e+09  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_hot_posts.head() # Inspect Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 1000\n",
    "is the Maximum Number of Posts the Reddit API could scrape automatically due to Reddit's limit on its API. It was by far the simplest of the 3 scraping mechanisms to use but it did not give me enough data. My target was at least 5,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I made an illustration during the COVID-19 loc...</td>\n",
       "      <td>2030</td>\n",
       "      <td>gwfbpd</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/x38ytci5lv251.jpg</td>\n",
       "      <td>77</td>\n",
       "      <td></td>\n",
       "      <td>1.591297e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I did some linework first time in many years</td>\n",
       "      <td>1633</td>\n",
       "      <td>e89e61</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/i3l3tsnwql341.png</td>\n",
       "      <td>32</td>\n",
       "      <td></td>\n",
       "      <td>1.575924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spongebob &amp; Patrick Minimal portrait</td>\n",
       "      <td>1578</td>\n",
       "      <td>eza5r1</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/iy28ekav54f41.jpg</td>\n",
       "      <td>60</td>\n",
       "      <td></td>\n",
       "      <td>1.580941e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drew a Casio Baby-G.</td>\n",
       "      <td>1451</td>\n",
       "      <td>ibdnt0</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/vrnv2jd19kh51.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>1.597698e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The designers at Snapchat be like</td>\n",
       "      <td>1446</td>\n",
       "      <td>cq7ydh</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/rosbdsir8eg31.jpg</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "      <td>1.565808e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  I made an illustration during the COVID-19 loc...   2030  gwfbpd   \n",
       "1       I did some linework first time in many years   1633  e89e61   \n",
       "2               Spongebob & Patrick Minimal portrait   1578  eza5r1   \n",
       "3                               Drew a Casio Baby-G.   1451  ibdnt0   \n",
       "4                  The designers at Snapchat be like   1446  cq7ydh   \n",
       "\n",
       "          subreddit                                  url  num_comments body  \\\n",
       "0  AdobeIllustrator  https://i.redd.it/x38ytci5lv251.jpg            77        \n",
       "1  AdobeIllustrator  https://i.redd.it/i3l3tsnwql341.png            32        \n",
       "2  AdobeIllustrator  https://i.redd.it/iy28ekav54f41.jpg            60        \n",
       "3  AdobeIllustrator  https://i.redd.it/vrnv2jd19kh51.jpg            24        \n",
       "4  AdobeIllustrator  https://i.redd.it/rosbdsir8eg31.jpg            66        \n",
       "\n",
       "        created  \n",
       "0  1.591297e+09  \n",
       "1  1.575924e+09  \n",
       "2  1.580941e+09  \n",
       "3  1.597698e+09  \n",
       "4  1.565808e+09  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_top_posts.head() # Inspect Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I made this wallpaper for mobile devices, any ...</td>\n",
       "      <td>5</td>\n",
       "      <td>lvozjc</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/fmh5wkkybik61.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1.614673e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Technique to create similar characters? l...</td>\n",
       "      <td>1</td>\n",
       "      <td>lvmyv0</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/3xrijcrowhk61.png</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1.614668e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beginner question here: how do I edit what thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>lvlfys</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://i.redd.it/v4rjnx7clhk61.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1.614664e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is it possible to align to a selected Key Obje...</td>\n",
       "      <td>1</td>\n",
       "      <td>lvl9uy</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://www.reddit.com/r/AdobeIllustrator/comm...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey everyone! I use the align to key object fe...</td>\n",
       "      <td>1.614663e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I convert line to shape without ending ...</td>\n",
       "      <td>1</td>\n",
       "      <td>lvhiq9</td>\n",
       "      <td>AdobeIllustrator</td>\n",
       "      <td>https://www.reddit.com/r/AdobeIllustrator/comm...</td>\n",
       "      <td>2</td>\n",
       "      <td>The image describes it best. I want to draw a ...</td>\n",
       "      <td>1.614655e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  I made this wallpaper for mobile devices, any ...      5  lvozjc   \n",
       "1  Best Technique to create similar characters? l...      1  lvmyv0   \n",
       "2  Beginner question here: how do I edit what thi...      1  lvlfys   \n",
       "3  Is it possible to align to a selected Key Obje...      1  lvl9uy   \n",
       "4  How do I convert line to shape without ending ...      1  lvhiq9   \n",
       "\n",
       "          subreddit                                                url  \\\n",
       "0  AdobeIllustrator                https://i.redd.it/fmh5wkkybik61.jpg   \n",
       "1  AdobeIllustrator                https://i.redd.it/3xrijcrowhk61.png   \n",
       "2  AdobeIllustrator                https://i.redd.it/v4rjnx7clhk61.jpg   \n",
       "3  AdobeIllustrator  https://www.reddit.com/r/AdobeIllustrator/comm...   \n",
       "4  AdobeIllustrator  https://www.reddit.com/r/AdobeIllustrator/comm...   \n",
       "\n",
       "   num_comments                                               body  \\\n",
       "0             1                                                      \n",
       "1             0                                                      \n",
       "2             3                                                      \n",
       "3             0  Hey everyone! I use the align to key object fe...   \n",
       "4             2  The image describes it best. I want to draw a ...   \n",
       "\n",
       "        created  \n",
       "0  1.614673e+09  \n",
       "1  1.614668e+09  \n",
       "2  1.614664e+09  \n",
       "3  1.614663e+09  \n",
       "4  1.614655e+09  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_new_posts.head() # Inspect Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Using PushShift API to Scrape<a name=\"push\"></a>\n",
    "\n",
    "The pushshift.io Reddit API was designed and created by the /r/datasets mod team to help provide enhanced functionality and search capabilities for searching Reddit comments and submissions. The project lead, /u/stuck_in_the_matrix, is the maintainer of the Reddit comment and submissions archives located at https://files.pushshift.io.\n",
    "\n",
    "This RESTful API gives full functionality for searching Reddit data and also includes the capability of creating powerful data aggregations. With this API, you can quickly find the data that you are interested in and find fascinating correlations.\n",
    "\n",
    "Source: https://github.com/pushshift/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subreddit_scrape (subreddit,start_date):\n",
    "    \n",
    "    url = 'https://api.pushshift.io/reddit/submission/search/' # My base link\n",
    "    \n",
    "    empty = [] # Empty string to tag on the Scraped Data\n",
    "    \n",
    "    while (start_date < 1614314325): # Set an Epoch Time Limit\n",
    "\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 100,\n",
    "            'after': start_date,\n",
    "            'sort_type' : 'created_utc',\n",
    "            'fields' : ['subreddit','title','selftext','created_utc','score','num_comments','subreddit_subscribers','full_link']\n",
    "        } # Define Parameters to scrape from Reddit\n",
    "\n",
    "        res = requests.get (url, params) # Combine parameters with URL\n",
    "\n",
    "        dataseries = res.json() # Extract .json data from URL page\n",
    "        \n",
    "        empty.extend(dataseries['data']) # Add Data to empty list\n",
    "        \n",
    "        sleep(3) # Sleep for 3 seconds so we don't get flagged by Reddit\n",
    "        \n",
    "        if len(dataseries['data']) == 100: # This is to ensure there is no error \n",
    "        #occurs if less than 100 posts returned\n",
    "        \n",
    "            start_date = dataseries['data'][99]['created_utc']\n",
    "            # Tag on the oldest date to our list and continue iterating\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            break\n",
    "        \n",
    "    df = pd.DataFrame(empty) # Convert lists to dataframe\n",
    "\n",
    "    return df\n",
    "\n",
    "# https://pushshift.io/api-parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "procreate = subreddit_scrape ('ProCreate',1546306316) # Start Jan 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Export PushShift API dataset to our Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission CSV is ready!\n"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame you created to a csv called 'procreate_finals.csv'\n",
    "procreate.to_csv('/Users/macbook/Google Drive/0. Ofilispeaks Business (Mac and Cloud)/9. Data Science/0. Python/General Assembly Training/submissions/Projects/Project 3/data/0_Scraped_Data/procreate_final.csv', index=False)\n",
    "print('Submission CSV is ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # 28,000!\n",
    "Is the maximum number of posts we were able to scrape with the PushShift API and this was for the ProCreate Reddit. It took the longest to execute of the three, but the reward for effort was worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_utc', 'full_link', 'num_comments', 'score', 'selftext',\n",
       "       'subreddit', 'subreddit_subscribers', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procreate.columns # Inspect Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procreate.shape # Inspect Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18999, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procreate[procreate['num_comments'] <= 2].shape # Check posts with comments less than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procreate[procreate['selftext'] == '[deleted]'].shape # Check posts with deleted self text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adobeillustrator = subreddit_scrape('AdobeIllustrator',1546306316) # Start Jan 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Export PushShift API dataset to our Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission CSV is ready!\n"
     ]
    }
   ],
   "source": [
    "# Write the DataFrame you created to a csv called 'adobeillustrators.csv'\n",
    "adobeillustrator.to_csv('/Users/macbook/Google Drive/0. Ofilispeaks Business (Mac and Cloud)/9. Data Science/0. Python/General Assembly Training/submissions/Projects/Project 3/data/0_Scraped_Data/adobeillustrator.csv', index=False)\n",
    "print('Submission CSV is ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19882, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adobeillustrator.shape # Inspect Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11930, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adobeillustrator[adobeillustrator['num_comments'] <= 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adobeillustrator[adobeillustrator['selftext'] == '[deleted]'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€œI am feeling ðŸ˜Š today\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
